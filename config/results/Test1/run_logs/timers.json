{
    "name": "root",
    "gauges": {
        "CubeAgent.Policy.Entropy.mean": {
            "value": 0.28032732009887695,
            "min": 0.2187384068965912,
            "max": 0.692983090877533,
            "count": 200
        },
        "CubeAgent.Policy.Entropy.sum": {
            "value": 1399.39404296875,
            "min": 1083.949462890625,
            "max": 3940.793212890625,
            "count": 200
        },
        "CubeAgent.Environment.EpisodeLength.mean": {
            "value": 282.52941176470586,
            "min": 50.20338983050848,
            "max": 299.0,
            "count": 200
        },
        "CubeAgent.Environment.EpisodeLength.sum": {
            "value": 4803.0,
            "min": 2891.0,
            "max": 6597.0,
            "count": 200
        },
        "CubeAgent.Step.mean": {
            "value": 999949.0,
            "min": 4963.0,
            "max": 999949.0,
            "count": 200
        },
        "CubeAgent.Step.sum": {
            "value": 999949.0,
            "min": 4963.0,
            "max": 999949.0,
            "count": 200
        },
        "CubeAgent.Policy.ExtrinsicValueEstimate.mean": {
            "value": 1.4381824731826782,
            "min": -0.20462621748447418,
            "max": 1.4671622514724731,
            "count": 200
        },
        "CubeAgent.Policy.ExtrinsicValueEstimate.sum": {
            "value": 120.80732727050781,
            "min": -22.304258346557617,
            "max": 127.42163848876953,
            "count": 200
        },
        "CubeAgent.Environment.CumulativeReward.mean": {
            "value": 5.699941491379457,
            "min": -1.1512931030372093,
            "max": 6.260533714294434,
            "count": 200
        },
        "CubeAgent.Environment.CumulativeReward.sum": {
            "value": 96.89900535345078,
            "min": -66.77499997615814,
            "max": 136.07800710201263,
            "count": 200
        },
        "CubeAgent.Policy.ExtrinsicReward.mean": {
            "value": 5.699941491379457,
            "min": -1.1512931030372093,
            "max": 6.260533714294434,
            "count": 200
        },
        "CubeAgent.Policy.ExtrinsicReward.sum": {
            "value": 96.89900535345078,
            "min": -66.77499997615814,
            "max": 136.07800710201263,
            "count": 200
        },
        "CubeAgent.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 200
        },
        "CubeAgent.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 200
        },
        "CubeAgent.Losses.PolicyLoss.mean": {
            "value": 0.023165471273276842,
            "min": 0.017334607810798017,
            "max": 0.03156178031173168,
            "count": 83
        },
        "CubeAgent.Losses.PolicyLoss.sum": {
            "value": 0.023165471273276842,
            "min": 0.017334607810798017,
            "max": 0.03156178031173168,
            "count": 83
        },
        "CubeAgent.Losses.ValueLoss.mean": {
            "value": 0.08794164793057875,
            "min": 0.019518822177567265,
            "max": 0.7077564561005795,
            "count": 83
        },
        "CubeAgent.Losses.ValueLoss.sum": {
            "value": 0.08794164793057875,
            "min": 0.019518822177567265,
            "max": 0.7077564561005795,
            "count": 83
        },
        "CubeAgent.Policy.LearningRate.mean": {
            "value": 1.9419993529998596e-07,
            "min": 1.9419993529998596e-07,
            "max": 0.00029638260120579997,
            "count": 83
        },
        "CubeAgent.Policy.LearningRate.sum": {
            "value": 1.9419993529998596e-07,
            "min": 1.9419993529998596e-07,
            "max": 0.00029638260120579997,
            "count": 83
        },
        "CubeAgent.Policy.Epsilon.mean": {
            "value": 0.1000647,
            "min": 0.1000647,
            "max": 0.1987942,
            "count": 83
        },
        "CubeAgent.Policy.Epsilon.sum": {
            "value": 0.1000647,
            "min": 0.1000647,
            "max": 0.1987942,
            "count": 83
        },
        "CubeAgent.Policy.Beta.mean": {
            "value": 0.003,
            "min": 0.003,
            "max": 0.003,
            "count": 83
        },
        "CubeAgent.Policy.Beta.sum": {
            "value": 0.003,
            "min": 0.003,
            "max": 0.003,
            "count": 83
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1745849504",
        "python_version": "3.9.21 (main, Dec 11 2024, 16:35:24) [MSC v.1929 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\senne\\anaconda3\\envs\\VRExperience\\Scripts\\mlagents-learn CubeAgent.yaml --run-id=Test1 --force",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.7.1+cu110",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1745850283"
    },
    "total": 778.3389463,
    "count": 1,
    "self": 0.004285100000060993,
    "children": {
        "run_training.setup": {
            "total": 0.058458699999999975,
            "count": 1,
            "self": 0.058458699999999975
        },
        "TrainerController.start_learning": {
            "total": 778.2762025,
            "count": 1,
            "self": 0.8311700000024302,
            "children": {
                "TrainerController._reset_env": {
                    "total": 6.388428299999999,
                    "count": 1,
                    "self": 6.388428299999999
                },
                "TrainerController.advance": {
                    "total": 771.0104623999976,
                    "count": 46047,
                    "self": 0.6200704000025326,
                    "children": {
                        "env_step": {
                            "total": 554.3973413000066,
                            "count": 46047,
                            "self": 434.95467930001354,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 118.99902589999797,
                                    "count": 46047,
                                    "self": 2.079334699994348,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 116.91969120000363,
                                            "count": 41694,
                                            "self": 116.91969120000363
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.4436360999950617,
                                    "count": 46047,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 772.0247084999977,
                                            "count": 46047,
                                            "is_parallel": true,
                                            "self": 383.6978431000018,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0005518999999996055,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00015739999999997423,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.00039449999999963126,
                                                            "count": 4,
                                                            "is_parallel": true,
                                                            "self": 0.00039449999999963126
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 388.3263134999959,
                                                    "count": 46047,
                                                    "is_parallel": true,
                                                    "self": 6.751230199994495,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 6.324474700013315,
                                                            "count": 46047,
                                                            "is_parallel": true,
                                                            "self": 6.324474700013315
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 356.64765419999844,
                                                            "count": 46047,
                                                            "is_parallel": true,
                                                            "self": 356.64765419999844
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 18.60295439998963,
                                                            "count": 46047,
                                                            "is_parallel": true,
                                                            "self": 5.2332319999948,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 13.369722399994831,
                                                                    "count": 184188,
                                                                    "is_parallel": true,
                                                                    "self": 13.369722399994831
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 215.99305069998843,
                            "count": 46047,
                            "self": 1.5805641999990598,
                            "children": {
                                "process_trajectory": {
                                    "total": 102.26332399998917,
                                    "count": 46047,
                                    "self": 102.14973059998916,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.11359340000001339,
                                            "count": 2,
                                            "self": 0.11359340000001339
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 112.14916250000022,
                                    "count": 83,
                                    "self": 74.01412930000046,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 38.135033199999754,
                                            "count": 2739,
                                            "self": 38.135033199999754
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 3.9999997625272954e-07,
                    "count": 1,
                    "self": 3.9999997625272954e-07
                },
                "TrainerController._save_models": {
                    "total": 0.046141400000010435,
                    "count": 1,
                    "self": 0.01037399999995614,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.035767400000054295,
                            "count": 1,
                            "self": 0.035767400000054295
                        }
                    }
                }
            }
        }
    }
}